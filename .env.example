# Medical Chatbot Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# Required API Keys
# =============================================================================

# Groq API Key (Required)
# Get your free API key from: https://console.groq.com/
# This is required for LLaMA 3.1 model access
GROQ_API_KEY=your_groq_api_key_here

# HuggingFace Token (Optional)
# Get your token from: https://huggingface.co/settings/tokens
# Only needed for accessing gated models or higher rate limits
HF_TOKEN=your_huggingface_token_here

# =============================================================================
# Application Configuration
# =============================================================================

# Flask Environment
# Options: development, production, testing
FLASK_ENV=development

# Flask Debug Mode
# Set to False in production
FLASK_DEBUG=True

# Application Port
# Default port for the Flask application
FLASK_PORT=5000

# Application Host
# Use 0.0.0.0 to allow external connections
FLASK_HOST=127.0.0.1

# Secret Key for Flask Sessions
# Generate a secure random key for production
# You can use: python -c "import secrets; print(secrets.token_hex())"
SECRET_KEY=your-secret-key-change-this-in-production

# =============================================================================
# AI Model Configuration
# =============================================================================

# Groq Model Selection
# Available models: llama-3.1-8b-instant, llama-3.1-70b-versatile, mixtral-8x7b-32768
GROQ_MODEL_NAME=llama-3.1-8b-instant

# Model Temperature (0.0 to 1.0)
# Lower values = more deterministic responses
MODEL_TEMPERATURE=0.3

# Maximum Tokens per Response
# Adjust based on your needs and API limits
MAX_TOKENS=512

# Model Timeout (seconds)
# How long to wait for model response
MODEL_TIMEOUT=30

# =============================================================================
# Vector Database Configuration
# =============================================================================

# FAISS Database Path
# Where to store the vector database files
DB_FAISS_PATH=vector_store/db_faiss

# Source Data Path
# Directory containing PDF files to process
DATA_PATH=data/

# Text Processing Settings
# Optimal chunk size for medical documents
CHUNK_SIZE=500

# Overlap between text chunks (maintains context)
CHUNK_OVERLAP=50

# Top-K Results for Similarity Search
# Number of relevant chunks to retrieve
RETRIEVAL_K=3

# Similarity Score Threshold (0.0 to 1.0)
# Higher values = more strict similarity matching
SIMILARITY_THRESHOLD=0.7

# =============================================================================
# Embedding Model Configuration
# =============================================================================

# Sentence Transformer Model
# Options: all-MiniLM-L6-v2, all-mpnet-base-v2, etc.
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Embedding Device
# Options: cpu, cuda (if GPU available)
EMBEDDING_DEVICE=cpu

# =============================================================================
# Logging Configuration
# =============================================================================

# Log Level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log Directory
# Where to store application logs
LOG_DIR=logs

# Log File Rotation
# Maximum size per log file (MB)
LOG_MAX_SIZE=10

# Number of backup log files to keep
LOG_BACKUP_COUNT=5

# Console Logging
# Whether to also log to console/stdout
LOG_TO_CONSOLE=True

# =============================================================================
# Security Configuration
# =============================================================================

# Rate Limiting (if enabled)
# Requests per minute per IP
RATE_LIMIT_PER_MINUTE=60

# Request Timeout (seconds)
REQUEST_TIMEOUT=300

# Maximum Query Length (characters)
MAX_QUERY_LENGTH=1000

# Session Timeout (minutes)
SESSION_TIMEOUT=60

# =============================================================================
# Performance Configuration
# =============================================================================

# Flask Workers (for production with Gunicorn)
WORKERS=4

# Worker Connections
WORKER_CONNECTIONS=1000

# Worker Timeout (seconds)
WORKER_TIMEOUT=30

# Preload Application
PRELOAD_APP=True

# =============================================================================
# Monitoring & Health Check Configuration
# =============================================================================

# Health Check Endpoint
HEALTH_CHECK_ENDPOINT=/health

# Metrics Collection (if Prometheus enabled)
ENABLE_METRICS=False
METRICS_ENDPOINT=/metrics

# =============================================================================
# Database Configuration (Future Features)
# =============================================================================

# PostgreSQL Configuration (for user data, chat history)
# DATABASE_URL=postgresql://user:password@localhost:5432/medical_chatbot

# Redis Configuration (for caching, sessions)
# REDIS_URL=redis://localhost:6379/0

# =============================================================================
# External Services Configuration
# =============================================================================

# Email Configuration (for notifications)
# SMTP_HOST=smtp.gmail.com
# SMTP_PORT=587
# SMTP_USER=your-email@gmail.com
# SMTP_PASSWORD=your-app-password
# SMTP_USE_TLS=True

# Webhook URLs (for notifications)
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/your/webhook/url
# DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your/webhook/url

# =============================================================================
# Development & Testing Configuration
# =============================================================================

# Testing Database Path (separate from production)
TEST_DB_FAISS_PATH=test_vector_store/db_faiss

# Test Data Path
TEST_DATA_PATH=test_data/

# Skip Model Loading in Tests
SKIP_MODEL_LOADING=False

# Mock API Responses
MOCK_API_RESPONSES=False

# =============================================================================
# Docker Configuration
# =============================================================================

# Container Name
CONTAINER_NAME=medical-chatbot

# Docker Network
DOCKER_NETWORK=medical-network

# Volume Mounts
VECTOR_STORE_VOLUME=./vector_store:/app/vector_store
LOGS_VOLUME=./logs:/app/logs
DATA_VOLUME=./data:/app/data

# =============================================================================
# Backup Configuration
# =============================================================================

# Backup Directory
BACKUP_DIR=/backups

# Backup Schedule (cron format)
BACKUP_SCHEDULE=0 2 * * *

# Number of backups to keep
BACKUP_RETENTION_DAYS=7

# =============================================================================
# Feature Flags
# =============================================================================

# Enable experimental features
ENABLE_EXPERIMENTAL_FEATURES=False

# Enable conversation memory
ENABLE_CONVERSATION_MEMORY=False

# Enable multi-language support
ENABLE_MULTI_LANGUAGE=False

# Enable citation tracking
ENABLE_CITATIONS=False

# =============================================================================
# SSL/TLS Configuration (Production)
# =============================================================================

# SSL Certificate Path
# SSL_CERT_PATH=/etc/ssl/certs/your-cert.pem
# SSL_KEY_PATH=/etc/ssl/private/your-key.pem

# Force HTTPS
# FORCE_HTTPS=True

# =============================================================================
# Instructions
# =============================================================================

# 1. Copy this file to .env: cp .env.example .env
# 2. Fill in your actual values, especially API keys
# 3. Never commit .env file to version control
# 4. Use different .env files for different environments
# 5. For production, use secure secret management services

# Need help?
# - Groq API: https://console.groq.com/docs/quickstart
# - HuggingFace: https://huggingface.co/docs/hub/security-tokens
# - Flask Config: https://flask.palletsprojects.com/en/2.3.x/config/
# - Docker: https://docs.docker.com/compose/environment-variables/
