# ğŸ“ Project Structure Documentation

> Detailed breakdown of the Medical Chatbot project architecture and file organization

## ğŸ—ï¸ Project Overview

The Medical Chatbot is organized following Python best practices with a modular, scalable architecture. The project uses a component-based design that separates concerns and enables easy maintenance and testing.

```
Medical-Chatbot/
â”œâ”€â”€ ğŸ“„ Configuration Files
â”œâ”€â”€ ğŸ³ Deployment Files  
â”œâ”€â”€ ğŸ“š Application Code
â”œâ”€â”€ ğŸ“Š Data & Models
â”œâ”€â”€ ğŸ“ Documentation
â””â”€â”€ ğŸ”§ Development Tools
```

## ğŸ“‚ Complete Directory Structure

```
Medical-Chatbot/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ DEPLOYMENT_GUIDE.md          # Deployment instructions
â”œâ”€â”€ ğŸ“„ API_DOCUMENTATION.md         # API reference guide
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ pyproject.toml              # Modern Python project config
â”œâ”€â”€ ğŸ“„ setup.py                    # Package installation script
â”œâ”€â”€ ğŸ“„ uv.lock                     # Dependency lock file
â”œâ”€â”€ ğŸ“„ .env.example                # Environment variables template
â”‚
â”œâ”€â”€ ğŸ³ Dockerfile                   # Container configuration
â”œâ”€â”€ ğŸ³ docker-compose.yml          # Multi-container deployment
â”œâ”€â”€ ğŸ”§ Jenkinsfile                 # CI/CD pipeline configuration
â”‚
â”œâ”€â”€ ğŸš€ main.py                     # Entry point (simple version)
â”œâ”€â”€ ğŸš€ startup.py                  # Production startup script
â”œâ”€â”€ ğŸ“Š init_vector_store.py        # Vector database initialization
â”œâ”€â”€ ğŸ§ª test_deployment.py          # Deployment testing
â”‚
â”œâ”€â”€ ğŸ“š app/                        # Main application package
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py             # Package initialization
â”‚   â”œâ”€â”€ ğŸŒ application.py          # Flask web application
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§  components/             # Core AI/ML components
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“Š data_loader.py      # PDF processing pipeline
â”‚   â”‚   â”œâ”€â”€ ğŸ”¤ embeddings.py       # Text embedding models
â”‚   â”‚   â”œâ”€â”€ ğŸ¤– llm.py             # Language model integration
â”‚   â”‚   â”œâ”€â”€ ğŸ“– pdf_loader.py       # PDF document processing
â”‚   â”‚   â”œâ”€â”€ ğŸ” retriever.py        # Question-answering chain
â”‚   â”‚   â””â”€â”€ ğŸ’¾ vector_store.py     # FAISS database management
â”‚   â”‚
â”‚   â”œâ”€â”€ âš™ï¸ config/                # Configuration management
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ config.py           # Application settings
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ› ï¸ common/                # Shared utilities
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ âš ï¸ custom_exception.py # Error handling
â”‚   â”‚   â””â”€â”€ ğŸ“ logger.py           # Logging configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¨ templates/             # Web interface templates
â”‚   â”‚   â””â”€â”€ ğŸ“„ index.html          # Main chat interface
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ __pycache__/           # Python bytecode cache
â”‚
â”œâ”€â”€ ğŸ“Š data/                       # Medical literature storage
â”‚   â”œâ”€â”€ ğŸ“– Oxford_Handbook_Clinical_Medicine.pdf
â”‚   â””â”€â”€ ğŸ“– Gale_Encyclopedia_Medicine.pdf
â”‚
â”œâ”€â”€ ğŸ’¾ vector_store/              # FAISS vector database
â”‚   â””â”€â”€ ğŸ“ db_faiss/
â”‚       â”œâ”€â”€ ğŸ“„ index.faiss         # Vector index file
â”‚       â””â”€â”€ ğŸ“„ index.pkl           # Metadata pickle file
â”‚
â”œâ”€â”€ ğŸ“ logs/                      # Application logs
â”‚   â”œâ”€â”€ ğŸ“„ log_2025-07-17.log
â”‚   â”œâ”€â”€ ğŸ“„ log_2025-07-19.log
â”‚   â”œâ”€â”€ ğŸ“„ log_2025-07-20.log
â”‚   â””â”€â”€ ğŸ“„ log_2025-07-21.log
â”‚
â”œâ”€â”€ ğŸ”§ custom_jenkins/            # Custom Jenkins configuration
â”‚   â””â”€â”€ ğŸ³ Dockerfile             # Jenkins container setup
â”‚
â””â”€â”€ ğŸ“¦ medical_chatbot.egg-info/  # Package metadata
    â”œâ”€â”€ ğŸ“„ dependency_links.txt
    â”œâ”€â”€ ğŸ“„ PKG-INFO
    â”œâ”€â”€ ğŸ“„ requires.txt
    â”œâ”€â”€ ğŸ“„ SOURCES.txt
    â””â”€â”€ ğŸ“„ top_level.txt
```

## ğŸ” Detailed File Analysis

### ğŸ“„ Root Configuration Files

#### `requirements.txt`
```txt
langchain>=0.1.0           # LLM orchestration framework
langchain_community>=0.3.0 # Community extensions
langchain_huggingface      # HuggingFace integrations
langchain-groq            # Groq API integration
faiss-cpu                 # Vector similarity search
pypdf                     # PDF document processing
python-dotenv             # Environment variable management
flask                     # Web framework
huggingface-hub          # Model hub access
sentence-transformers    # Text embeddings
```

#### `setup.py`
```python
from setuptools import setup, find_packages

# Package configuration for pip installation
setup(
    name="Medical-Chatbot",
    version="0.1.0", 
    author="Anish Konda",
    packages=find_packages(),
    install_requires=[...],  # From requirements.txt
)
```

#### `pyproject.toml`
Modern Python project configuration following PEP 518 standards.

### ğŸ³ Deployment Files

#### `Dockerfile`
```dockerfile
FROM python:3.10-slim       # Lightweight Python base image
ENV PYTHONDONTWRITEBYTECODE=1  # Prevent .pyc files
ENV PYTHONUNBUFFERED=1      # Real-time output
WORKDIR /app                # Application directory
# System dependencies, Python packages, app setup
EXPOSE 5000                 # Flask default port
CMD ["python", "app/application.py"]
```

#### `Jenkinsfile`
CI/CD pipeline configuration for automated:
- Code checkout and testing
- Docker image building
- Deployment automation
- Health checks and rollback

### ğŸ“š Application Code Structure

#### `app/application.py` - Web Server
```python
# Main Flask application
# - Route handling (/,  /clear)
# - Session management
# - Template rendering
# - Error handling integration
# - QA chain orchestration
```

**Key Features:**
- Session-based chat history
- Custom Jinja2 filters for formatting
- Error boundary implementation
- Integration with AI components

#### `app/components/` - AI/ML Core

##### `llm.py` - Language Model Integration
```python
from langchain_groq import ChatGroq

def load_llm(model_name="llama-3.1-8b-instant"):
    """Load LLaMA model via Groq API"""
    return ChatGroq(
        groq_api_key=GROQ_API_KEY,
        model_name=model_name,
        temperature=0.3,        # Balanced creativity
        max_tokens=512,         # Response length limit
    )
```

##### `embeddings.py` - Text Embeddings
```python
from sentence_transformers import SentenceTransformer

def get_embedding_model():
    """Load sentence transformer for text embeddings"""
    return SentenceTransformer('all-MiniLM-L6-v2')
    # Fast, efficient embeddings for semantic search
```

##### `vector_store.py` - FAISS Database
```python
from langchain_community.vectorstores import FAISS

def load_vector_store():
    """Load existing FAISS vector database"""
    return FAISS.load_local(
        DB_FAISS_PATH,
        embedding_model,
        allow_dangerous_deserialization=True
    )

def save_vector_store(text_chunks):
    """Create new vector database from documents"""
    db = FAISS.from_documents(text_chunks, embedding_model)
    db.save_local(DB_FAISS_PATH)
```

##### `pdf_loader.py` - Document Processing
```python
from pypdf import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter

def load_pdf_files():
    """Extract text from medical PDF files"""
    
def create_text_chunks(documents):
    """Split documents into searchable chunks"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,      # 500 characters
        chunk_overlap=CHUNK_OVERLAP # 50 character overlap
    )
```

##### `retriever.py` - QA Chain Orchestration
```python
from langchain.chains import RetrievalQA

def create_qa_chain():
    """Create question-answering chain"""
    qa_chain = RetrievalQA.from_chain_type(
        llm=load_llm(),
        chain_type="stuff",                    # Concatenate context
        retriever=db.as_retriever(            # Vector search
            search_kwargs={'k': 3}             # Top 3 results
        ),
        chain_type_kwargs={
            'prompt': set_custom_prompt()      # Medical-specific prompt
        }
    )
```

##### `data_loader.py` - Processing Pipeline
```python
def process_and_store_pdfs():
    """Complete pipeline: PDF â†’ Text â†’ Chunks â†’ Vectors"""
    documents = load_pdf_files()      # Extract text
    text_chunks = create_text_chunks() # Split into chunks  
    save_vector_store(text_chunks)    # Create FAISS index
```

#### `app/config/config.py` - Configuration Management
```python
import os

# API Configuration
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
HF_TOKEN = os.environ.get("HF_TOKEN")

# Model Settings
GROQ_MODEL_NAME = "llama3-8b-8192"

# Database Paths
DB_FAISS_PATH = "vector_store/db_faiss"
DATA_PATH = "data/"

# Processing Parameters
CHUNK_SIZE = 500          # Optimal for medical text
CHUNK_OVERLAP = 50        # Maintains context continuity
```

#### `app/common/` - Shared Utilities

##### `logger.py` - Logging System
```python
import logging
from logging.handlers import RotatingFileHandler

def get_logger(name):
    """Create configured logger with file rotation"""
    logger = logging.getLogger(name)
    
    # File handler with rotation (10MB, 5 backups)
    file_handler = RotatingFileHandler(
        f'logs/log_{datetime.now().strftime("%Y-%m-%d")}.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
```

##### `custom_exception.py` - Error Handling
```python
class CustomException(Exception):
    """Enhanced exception with context and chaining"""
    
    def __init__(self, message, original_exception=None):
        super().__init__(message)
        self.original_exception = original_exception
        self.timestamp = datetime.now()
```

### ğŸ¨ Web Interface

#### `app/templates/index.html`
Modern, responsive chat interface featuring:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Modern fonts and icons -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <!-- Gradient background with glassmorphism effects -->
    <!-- Responsive chat container -->
    <!-- Message bubbles with user/assistant styling -->
    <!-- Auto-scroll and typing indicators -->
    <!-- Error handling with elegant display -->
</body>
</html>
```

**UI Features:**
- ğŸ¨ Modern glassmorphism design
- ğŸ“± Fully responsive layout
- ğŸ’¬ Chat bubble interface
- âš¡ Real-time message updates
- ğŸš¨ Elegant error display
- ğŸ”„ Auto-scroll to latest messages

## ğŸ’¾ Data Architecture

### Vector Database Structure

```
vector_store/db_faiss/
â”œâ”€â”€ index.faiss          # Binary vector index (FAISS format)
â”‚   â”œâ”€â”€ Vector dimensions: 384 (all-MiniLM-L6-v2)
â”‚   â”œâ”€â”€ Index type: IndexFlatL2 (exact search)
â”‚   â”œâ”€â”€ Document count: ~1,247 chunks
â”‚   â””â”€â”€ Total size: ~15MB
â”‚
â””â”€â”€ index.pkl           # Metadata pickle file
    â”œâ”€â”€ Document mappings
    â”œâ”€â”€ Source file references  
    â”œâ”€â”€ Chunk boundaries
    â””â”€â”€ Embedding metadata
```

### Document Processing Flow

```
ğŸ“– Medical PDFs (data/)
    â†“
ğŸ“ Text Extraction (PyPDF)
    â†“  
ğŸ“Š Text Chunking (500 chars, 50 overlap)
    â†“
ğŸ”¤ Embedding Generation (SentenceTransformer)
    â†“
ğŸ’¾ Vector Storage (FAISS)
    â†“
ğŸ” Semantic Search (Similarity)
    â†“
ğŸ¤– Context Retrieval (Top-K)
    â†“
ğŸ’¬ AI Response (LLaMA 3.1)
```

## ğŸ”§ Development Workflow

### Local Development Setup

1. **Environment Preparation**
   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Configuration**
   ```bash
   cp .env.example .env
   # Add GROQ_API_KEY
   ```

3. **Database Initialization**
   ```bash
   python app/components/data_loader.py
   ```

4. **Application Start**
   ```bash
   python app/application.py
   ```

### Testing Structure

```
tests/                    # Test directory (to be created)
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_llm.py      # LLM integration tests
â”‚   â”œâ”€â”€ test_vector_store.py  # Vector database tests
â”‚   â”œâ”€â”€ test_pdf_loader.py    # Document processing tests
â”‚   â””â”€â”€ test_retriever.py     # QA chain tests
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_api.py      # API endpoint tests
â”‚   â””â”€â”€ test_workflow.py # End-to-end tests
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample.pdf       # Test documents
    â””â”€â”€ expected_responses.json
```

### Code Quality Tools

```bash
# Linting and formatting
pip install black flake8 isort mypy

# Format code
black app/
isort app/

# Type checking  
mypy app/

# Linting
flake8 app/
```

## ğŸš€ Production Considerations

### Performance Optimization

1. **Vector Search Optimization**
   - FAISS index tuning for large datasets
   - Approximate search for speed (IndexIVFFlat)
   - GPU acceleration for embeddings

2. **Caching Strategy**
   - Redis for frequent queries
   - Vector search result caching
   - Embedding computation caching

3. **Scaling Architecture**
   ```
   Load Balancer (Nginx)
       â†“
   Flask App Instances (3+)
       â†“
   Shared Vector Store (NFS/S3)
       â†“
   Shared Cache (Redis Cluster)
   ```

### Security Enhancements

1. **Input Validation**
   ```python
   from wtforms import Form, TextAreaField, validators
   
   class QueryForm(Form):
       prompt = TextAreaField('Query', [
           validators.Length(min=1, max=1000),
           validators.DataRequired()
       ])
   ```

2. **Rate Limiting**
   ```python
   from flask_limiter import Limiter
   
   limiter = Limiter(
       app,
       key_func=get_remote_address,
       default_limits=["100 per hour"]
   )
   ```

3. **Authentication** (Future Enhancement)
   ```python
   from flask_jwt_extended import JWTManager
   
   # JWT token-based authentication
   # User session management
   # API key validation
   ```

## ğŸ“Š Monitoring & Observability

### Logging Strategy

```python
# app/common/logger.py configuration
LOGGING_CONFIG = {
    'version': 1,
    'handlers': {
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/app.log',
            'maxBytes': 10*1024*1024,  # 10MB
            'backupCount': 5,
            'formatter': 'detailed'
        },
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'simple'
        }
    },
    'loggers': {
        'app': {
            'handlers': ['file', 'console'],
            'level': 'INFO'
        }
    }
}
```

### Metrics Collection

```python
# Prometheus metrics (future enhancement)
from prometheus_client import Counter, Histogram

QUERY_COUNT = Counter('medical_queries_total', 'Total queries')
RESPONSE_TIME = Histogram('query_duration_seconds', 'Response time')
ERROR_COUNT = Counter('query_errors_total', 'Query errors')
```

## ğŸ”„ Future Enhancements

### Planned Features

1. **API Improvements**
   - RESTful JSON API
   - GraphQL endpoint
   - WebSocket for real-time chat

2. **AI Enhancements**
   - Multi-model support
   - Conversation memory
   - Citation tracking
   - Confidence scoring

3. **User Features**
   - User authentication
   - Chat history persistence
   - Favorite responses
   - Export conversations

4. **Medical Features**
   - Specialized medical models
   - Drug interaction checking
   - Symptom analysis
   - Medical image analysis

### Architecture Evolution

```
Current: Monolithic Flask App
    â†“
Phase 1: Microservices
    â”œâ”€â”€ API Gateway
    â”œâ”€â”€ Chat Service
    â”œâ”€â”€ Vector Search Service
    â””â”€â”€ LLM Service
    â†“
Phase 2: Cloud-Native
    â”œâ”€â”€ Kubernetes Deployment
    â”œâ”€â”€ Managed Vector Database
    â”œâ”€â”€ Serverless Functions
    â””â”€â”€ CDN Distribution
```

---

## ğŸ“ Support & Contributing

### File-Specific Issues

- **PDF Processing**: Check `app/components/pdf_loader.py`
- **Vector Search**: Debug `app/components/vector_store.py`
- **AI Responses**: Investigate `app/components/llm.py`
- **Web Interface**: Examine `app/templates/index.html`

### Contributing Guidelines

1. **File Naming Convention**: snake_case for Python, kebab-case for configs
2. **Import Organization**: Standard library â†’ Third-party â†’ Local imports
3. **Documentation**: Docstrings for all functions and classes
4. **Error Handling**: Use custom exceptions with proper logging

---

This structure documentation provides a comprehensive understanding of how the Medical Chatbot project is organized and how each component contributes to the overall functionality.
