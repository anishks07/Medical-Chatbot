# üìÅ Project Structure Documentation

> Detailed breakdown of the Medical Chatbot project architecture and file organization

## üèóÔ∏è Project Overview

The Medical Chatbot is organized following Python best practices with a modular, scalable architecture. The project uses a component-based design that separates concerns and enables easy maintenance and testing.

```
Medical-Chatbot/
‚îú‚îÄ‚îÄ üìÑ Configuration Files
‚îú‚îÄ‚îÄ üê≥ Deployment Files  
‚îú‚îÄ‚îÄ üìö Application Code
‚îú‚îÄ‚îÄ üìä Data & Models
‚îú‚îÄ‚îÄ üìù Documentation
‚îî‚îÄ‚îÄ üîß Development Tools
```

## üìÇ Complete Directory Structure

```
Medical-Chatbot/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                    # Main project documentation
‚îú‚îÄ‚îÄ üìÑ DEPLOYMENT_GUIDE.md          # Deployment instructions
‚îú‚îÄ‚îÄ üìÑ API_DOCUMENTATION.md         # API reference guide
‚îú‚îÄ‚îÄ üìÑ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ üìÑ pyproject.toml              # Modern Python project config
‚îú‚îÄ‚îÄ üìÑ setup.py                    # Package installation script
‚îú‚îÄ‚îÄ üìÑ uv.lock                     # Dependency lock file
‚îú‚îÄ‚îÄ üìÑ .env.example                # Environment variables template
‚îÇ
‚îú‚îÄ‚îÄ üê≥ Dockerfile                   # Container configuration
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml          # Multi-container deployment
‚îú‚îÄ‚îÄ üîß Jenkinsfile                 # CI/CD pipeline configuration
‚îÇ
‚îú‚îÄ‚îÄ üöÄ main.py                     # Entry point (simple version)
‚îú‚îÄ‚îÄ üöÄ startup.py                  # Production startup script
‚îú‚îÄ‚îÄ üìä init_vector_store.py        # Vector database initialization
‚îú‚îÄ‚îÄ üß™ test_deployment.py          # Deployment testing
‚îÇ
‚îú‚îÄ‚îÄ üìö app/                        # Main application package
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py             # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ üåê application.py          # Flask web application
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üß† components/             # Core AI/ML components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìä data_loader.py      # PDF processing pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üî§ embeddings.py       # Text embedding models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ü§ñ llm.py             # Language model integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìñ pdf_loader.py       # PDF document processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üîç retriever.py        # Question-answering chain
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üíæ vector_store.py     # FAISS database management
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ‚öôÔ∏è config/                # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ config.py           # Application settings
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üõ†Ô∏è common/                # Shared utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚ö†Ô∏è custom_exception.py # Error handling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìù logger.py           # Logging configuration
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üé® templates/             # Web interface templates
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ index.html          # Main chat interface
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ __pycache__/           # Python bytecode cache
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                       # Medical literature storage
‚îÇ   ‚îú‚îÄ‚îÄ üìñ Oxford_Handbook_Clinical_Medicine.pdf
‚îÇ   ‚îî‚îÄ‚îÄ üìñ Gale_Encyclopedia_Medicine.pdf
‚îÇ
‚îú‚îÄ‚îÄ üíæ vector_store/              # FAISS vector database
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ db_faiss/
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ index.faiss         # Vector index file
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ index.pkl           # Metadata pickle file
‚îÇ
‚îú‚îÄ‚îÄ üìù logs/                      # Application logs
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ log_2025-07-17.log
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ log_2025-07-19.log
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ log_2025-07-20.log
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ log_2025-07-21.log
‚îÇ
‚îú‚îÄ‚îÄ üîß custom_jenkins/            # Custom Jenkins configuration
‚îÇ   ‚îî‚îÄ‚îÄ üê≥ Dockerfile             # Jenkins container setup
‚îÇ
‚îî‚îÄ‚îÄ üì¶ medical_chatbot.egg-info/  # Package metadata
    ‚îú‚îÄ‚îÄ üìÑ dependency_links.txt
    ‚îú‚îÄ‚îÄ üìÑ PKG-INFO
    ‚îú‚îÄ‚îÄ üìÑ requires.txt
    ‚îú‚îÄ‚îÄ üìÑ SOURCES.txt
    ‚îî‚îÄ‚îÄ üìÑ top_level.txt
```

## üîç Detailed File Analysis

### üìÑ Root Configuration Files

#### `requirements.txt`
```txt
langchain>=0.1.0           # LLM orchestration framework
langchain_community>=0.3.0 # Community extensions
langchain_huggingface      # HuggingFace integrations
langchain-groq            # Groq API integration
faiss-cpu                 # Vector similarity search
pypdf                     # PDF document processing
python-dotenv             # Environment variable management
flask                     # Web framework
huggingface-hub          # Model hub access
sentence-transformers    # Text embeddings
```

#### `setup.py`
```python
from setuptools import setup, find_packages

# Package configuration for pip installation
setup(
    name="Medical-Chatbot",
    version="0.1.0", 
    author="Anish Konda",
    packages=find_packages(),
    install_requires=[...],  # From requirements.txt
)
```

#### `pyproject.toml`
Modern Python project configuration following PEP 518 standards.

### üê≥ Deployment Files

#### `Dockerfile`
```dockerfile
FROM python:3.10-slim       # Lightweight Python base image
ENV PYTHONDONTWRITEBYTECODE=1  # Prevent .pyc files
ENV PYTHONUNBUFFERED=1      # Real-time output
WORKDIR /app                # Application directory
# System dependencies, Python packages, app setup
EXPOSE 5000                 # Flask default port
CMD ["python", "app/application.py"]
```

#### `Jenkinsfile`
CI/CD pipeline configuration for automated:
- Code checkout and testing
- Docker image building
- Deployment automation
- Health checks and rollback

### üìö Application Code Structure

#### `app/application.py` - Web Server
```python
# Main Flask application
# - Route handling (/,  /clear)
# - Session management
# - Template rendering
# - Error handling integration
# - QA chain orchestration
```

**Key Features:**
- Session-based chat history
- Custom Jinja2 filters for formatting
- Error boundary implementation
- Integration with AI components

#### `app/components/` - AI/ML Core

##### `llm.py` - Language Model Integration
```python
from langchain_groq import ChatGroq

def load_llm(model_name="llama-3.1-8b-instant"):
    """Load LLaMA model via Groq API"""
    return ChatGroq(
        groq_api_key=GROQ_API_KEY,
        model_name=model_name,
        temperature=0.3,        # Balanced creativity
        max_tokens=512,         # Response length limit
    )
```

##### `embeddings.py` - Text Embeddings
```python
from sentence_transformers import SentenceTransformer

def get_embedding_model():
    """Load sentence transformer for text embeddings"""
    return SentenceTransformer('all-MiniLM-L6-v2')
    # Fast, efficient embeddings for semantic search
```

##### `vector_store.py` - FAISS Database
```python
from langchain_community.vectorstores import FAISS

def load_vector_store():
    """Load existing FAISS vector database"""
    return FAISS.load_local(
        DB_FAISS_PATH,
        embedding_model,
        allow_dangerous_deserialization=True
    )

def save_vector_store(text_chunks):
    """Create new vector database from documents"""
    db = FAISS.from_documents(text_chunks, embedding_model)
    db.save_local(DB_FAISS_PATH)
```

##### `pdf_loader.py` - Document Processing
```python
from pypdf import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter

def load_pdf_files():
    """Extract text from medical PDF files"""
    
def create_text_chunks(documents):
    """Split documents into searchable chunks"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,      # 500 characters
        chunk_overlap=CHUNK_OVERLAP # 50 character overlap
    )
```

##### `retriever.py` - QA Chain Orchestration
```python
from langchain.chains import RetrievalQA

def create_qa_chain():
    """Create question-answering chain"""
    qa_chain = RetrievalQA.from_chain_type(
        llm=load_llm(),
        chain_type="stuff",                    # Concatenate context
        retriever=db.as_retriever(            # Vector search
            search_kwargs={'k': 3}             # Top 3 results
        ),
        chain_type_kwargs={
            'prompt': set_custom_prompt()      # Medical-specific prompt
        }
    )
```

##### `data_loader.py` - Processing Pipeline
```python
def process_and_store_pdfs():
    """Complete pipeline: PDF ‚Üí Text ‚Üí Chunks ‚Üí Vectors"""
    documents = load_pdf_files()      # Extract text
    text_chunks = create_text_chunks() # Split into chunks  
    save_vector_store(text_chunks)    # Create FAISS index
```

#### `app/config/config.py` - Configuration Management
```python
import os

# API Configuration
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
HF_TOKEN = os.environ.get("HF_TOKEN")

# Model Settings
GROQ_MODEL_NAME = "llama3-8b-8192"

# Database Paths
DB_FAISS_PATH = "vector_store/db_faiss"
DATA_PATH = "data/"

# Processing Parameters
CHUNK_SIZE = 500          # Optimal for medical text
CHUNK_OVERLAP = 50        # Maintains context continuity
```

#### `app/common/` - Shared Utilities

##### `logger.py` - Logging System
```python
import logging
from logging.handlers import RotatingFileHandler

def get_logger(name):
    """Create configured logger with file rotation"""
    logger = logging.getLogger(name)
    
    # File handler with rotation (10MB, 5 backups)
    file_handler = RotatingFileHandler(
        f'logs/log_{datetime.now().strftime("%Y-%m-%d")}.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
```

##### `custom_exception.py` - Error Handling
```python
class CustomException(Exception):
    """Enhanced exception with context and chaining"""
    
    def __init__(self, message, original_exception=None):
        super().__init__(message)
        self.original_exception = original_exception
        self.timestamp = datetime.now()
```

### üé® Web Interface

#### `app/templates/index.html`
Modern, responsive chat interface featuring:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Modern fonts and icons -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <!-- Gradient background with glassmorphism effects -->
    <!-- Responsive chat container -->
    <!-- Message bubbles with user/assistant styling -->
    <!-- Auto-scroll and typing indicators -->
    <!-- Error handling with elegant display -->
</body>
</html>
```

**UI Features:**
- üé® Modern glassmorphism design
- üì± Fully responsive layout
- üí¨ Chat bubble interface
- ‚ö° Real-time message updates
- üö® Elegant error display
- üîÑ Auto-scroll to latest messages

## üíæ Data Architecture

### Vector Database Structure

```
vector_store/db_faiss/
‚îú‚îÄ‚îÄ index.faiss          # Binary vector index (FAISS format)
‚îÇ   ‚îú‚îÄ‚îÄ Vector dimensions: 384 (all-MiniLM-L6-v2)
‚îÇ   ‚îú‚îÄ‚îÄ Index type: IndexFlatL2 (exact search)
‚îÇ   ‚îú‚îÄ‚îÄ Document count: ~1,247 chunks
‚îÇ   ‚îî‚îÄ‚îÄ Total size: ~15MB
‚îÇ
‚îî‚îÄ‚îÄ index.pkl           # Metadata pickle file
    ‚îú‚îÄ‚îÄ Document mappings
    ‚îú‚îÄ‚îÄ Source file references  
    ‚îú‚îÄ‚îÄ Chunk boundaries
    ‚îî‚îÄ‚îÄ Embedding metadata
```

### Document Processing Flow

```
üìñ Medical PDFs (data/)
    ‚Üì
üìù Text Extraction (PyPDF)
    ‚Üì  
üìä Text Chunking (500 chars, 50 overlap)
    ‚Üì
üî§ Embedding Generation (SentenceTransformer)
    ‚Üì
üíæ Vector Storage (FAISS)
    ‚Üì
üîç Semantic Search (Similarity)
    ‚Üì
ü§ñ Context Retrieval (Top-K)
    ‚Üì
üí¨ AI Response (LLaMA 3.1)
```

## üîß Development Workflow

### Local Development Setup

1. **Environment Preparation**
   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Configuration**
   ```bash
   cp .env.example .env
   # Add GROQ_API_KEY
   ```

3. **Database Initialization**
   ```bash
   python app/components/data_loader.py
   ```

4. **Application Start**
   ```bash
   python app/application.py
   ```

### Testing Structure

```
tests/                    # Test directory (to be created)
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_llm.py      # LLM integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_vector_store.py  # Vector database tests
‚îÇ   ‚îú‚îÄ‚îÄ test_pdf_loader.py    # Document processing tests
‚îÇ   ‚îî‚îÄ‚îÄ test_retriever.py     # QA chain tests
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py      # API endpoint tests
‚îÇ   ‚îî‚îÄ‚îÄ test_workflow.py # End-to-end tests
‚îî‚îÄ‚îÄ fixtures/
    ‚îú‚îÄ‚îÄ sample.pdf       # Test documents
    ‚îî‚îÄ‚îÄ expected_responses.json
```

### Code Quality Tools

```bash
# Linting and formatting
pip install black flake8 isort mypy

# Format code
black app/
isort app/

# Type checking  
mypy app/

# Linting
flake8 app/
```

## üöÄ Production Considerations

### Performance Optimization

1. **Vector Search Optimization**
   - FAISS index tuning for large datasets
   - Approximate search for speed (IndexIVFFlat)
   - GPU acceleration for embeddings

2. **Caching Strategy**
   - Redis for frequent queries
   - Vector search result caching
   - Embedding computation caching

3. **Scaling Architecture**
   ```
   Load Balancer (Nginx)
       ‚Üì
   Flask App Instances (3+)
       ‚Üì
   Shared Vector Store (NFS/S3)
       ‚Üì
   Shared Cache (Redis Cluster)
   ```

### Security Enhancements

1. **Input Validation**
   ```python
   from wtforms import Form, TextAreaField, validators
   
   class QueryForm(Form):
       prompt = TextAreaField('Query', [
           validators.Length(min=1, max=1000),
           validators.DataRequired()
       ])
   ```

2. **Rate Limiting**
   ```python
   from flask_limiter import Limiter
   
   limiter = Limiter(
       app,
       key_func=get_remote_address,
       default_limits=["100 per hour"]
   )
   ```

3. **Authentication** (Future Enhancement)
   ```python
   from flask_jwt_extended import JWTManager
   
   # JWT token-based authentication
   # User session management
   # API key validation
   ```

## üìä Monitoring & Observability

### Logging Strategy

```python
# app/common/logger.py configuration
LOGGING_CONFIG = {
    'version': 1,
    'handlers': {
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/app.log',
            'maxBytes': 10*1024*1024,  # 10MB
            'backupCount': 5,
            'formatter': 'detailed'
        },
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'simple'
        }
    },
    'loggers': {
        'app': {
            'handlers': ['file', 'console'],
            'level': 'INFO'
        }
    }
}
```

### Metrics Collection

```python
# Prometheus metrics (future enhancement)
from prometheus_client import Counter, Histogram

QUERY_COUNT = Counter('medical_queries_total', 'Total queries')
RESPONSE_TIME = Histogram('query_duration_seconds', 'Response time')
ERROR_COUNT = Counter('query_errors_total', 'Query errors')
```

## üîÑ Future Enhancements

### Planned Features

1. **API Improvements**
   - RESTful JSON API
   - GraphQL endpoint
   - WebSocket for real-time chat

2. **AI Enhancements**
   - Multi-model support
   - Conversation memory
   - Citation tracking
   - Confidence scoring

3. **User Features**
   - User authentication
   - Chat history persistence
   - Favorite responses
   - Export conversations

4. **Medical Features**
   - Specialized medical models
   - Drug interaction checking
   - Symptom analysis
   - Medical image analysis

### Architecture Evolution

```
Current: Monolithic Flask App
    ‚Üì
Phase 1: Microservices
    ‚îú‚îÄ‚îÄ API Gateway
    ‚îú‚îÄ‚îÄ Chat Service
    ‚îú‚îÄ‚îÄ Vector Search Service
    ‚îî‚îÄ‚îÄ LLM Service
    ‚Üì
Phase 2: Cloud-Native
    ‚îú‚îÄ‚îÄ Kubernetes Deployment
    ‚îú‚îÄ‚îÄ Managed Vector Database
    ‚îú‚îÄ‚îÄ Serverless Functions
    ‚îî‚îÄ‚îÄ CDN Distribution
```

---

## üìû Support & Contributing

### File-Specific Issues

- **PDF Processing**: Check `app/components/pdf_loader.py`
- **Vector Search**: Debug `app/components/vector_store.py`
- **AI Responses**: Investigate `app/components/llm.py`
- **Web Interface**: Examine `app/templates/index.html`

### Contributing Guidelines

1. **File Naming Convention**: snake_case for Python, kebab-case for configs
2. **Import Organization**: Standard library ‚Üí Third-party ‚Üí Local imports
3. **Documentation**: Docstrings for all functions and classes
4. **Error Handling**: Use custom exceptions with proper logging

---

This structure documentation provides a comprehensive understanding of how the Medical Chatbot project is organized and how each component contributes to the overall functionality.
